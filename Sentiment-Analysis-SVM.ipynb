{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "su_jcnYGm2Nb"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab import files\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V27zDizn6u33"
   },
   "source": [
    "## Called Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "IbDpctOdtOZL",
    "outputId": "e9849604-3ad4-498c-b3e2-07c353d06fa2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DiazAgfaNuribi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "my_df_training = pd.read_csv('clean_tweet_training.csv')\n",
    "tweet_text_training = my_df_training['text']\n",
    "target_training = my_df_training['target']\n",
    "X_training = tweet_text_training[pd.notnull(tweet_text_training)]\n",
    "Y_training = target_training[pd.notnull(tweet_text_training)]\n",
    "X_train_part1, X_train_part2, Y_train_part1, Y_train_part2 = train_test_split(X_training, Y_training, train_size=0.01, random_state=42)\n",
    "\n",
    "my_df_test = pd.read_csv('clean-tweet-test-fixed.csv')\n",
    "my_df_test = my_df_test[my_df_test.target != 2]\n",
    "tweet_text_test = my_df_test['text']\n",
    "target_test = my_df_test['target']\n",
    "X_test = tweet_text_test[pd.notnull(tweet_text_test)]\n",
    "Y_test = target_test[pd.notnull(tweet_text_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15927"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_part1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRllimC3683a"
   },
   "source": [
    "## Feature Extraction using Bag-of-Word <br>\n",
    "Untuk experiment ini, kita hanya akan menggunakan 700 kata yang paling sering muncul sebagai feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AC1YoMIqtWQ-",
    "outputId": "3b263218-f4c7-4fd5-e931-a335cd11e2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=700)\n",
    "X_training_vector = vectorizer.fit_transform(X_train_part1)\n",
    "print(\"Number of features:  %d\" % len(vectorizer.vocabulary_))\n",
    "X_test_vector = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLvR8CKc7LHw"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLWiFyo17RN7"
   },
   "source": [
    "## Feature Scaling\n",
    "Sebelum melakukan klasifikasi, sebaiknya dilakukan feature scaling agar nilai feature seragam (tidak terlalu besar atau terlalu kecil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "JAjlZmh4taa1",
    "outputId": "d2857c93-6eb5-4732-a3b0-91f8e5a36f5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DiazAgfaNuribi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler(with_mean = False)  \n",
    "scaler.fit(X_training_vector)\n",
    "\n",
    "X_training_vector = scaler.transform(X_training_vector)  \n",
    "X_test_vector = scaler.transform(X_test_vector)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOUlRIVS7XqC"
   },
   "source": [
    "## Classification using SVM <br>\n",
    "Klasifikasi menggunakan SVM dengan linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ2ms6TxtV_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Predicting...\n",
      "Accuracy: 0.7493036211699164\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = svm.SVC(kernel='linear')\n",
    "print(\"Training Classifier...\")\n",
    "clf.fit(X_training_vector, Y_train_part1)\n",
    "print(\"Predicting...\")\n",
    "prediction = clf.predict(X_test_vector)\n",
    "accuracy = accuracy_score(Y_test, prediction)\n",
    "print ('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg85QRHA76mh"
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUWKCskd8GO-"
   },
   "source": [
    "## Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVi6NBJ6uL-U"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'SVM_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzrhW4ZSuTMZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7493036211699164\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test_vector, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17YUmD_NuS2A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False), dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment Analysis - SVM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
